{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f8e6193",
   "metadata": {
    "id": "9f8e6193"
   },
   "source": [
    "# Diversify your stock porftolio with graph anayltics\n",
    "A couple of weeks ago, I stumbled upon the stock market volume analysis in Neo4j by Bryant Avey. It got me interested in how we could use graph analytics to analyze stock markets. After a bit of research, I found Spread of risk across financial markets research paper. The authors infer a network between stocks by examining the correlation between stocks and then use community detection algorithms to help with diversifying stock portfolios. As a conclusion of the research paper, the authors argue that this technique could reduce risk by diversifying your investment and, interestingly, increasing your profits.\n",
    "\n",
    "_Disclaimer: This is not financial advice, and you should do your own research before investing_\n",
    "\n",
    "We will be using a subset of Kaggle's NASDAQ-100 Stock Price dataset. The dataset contains price and volume information of 102 securities for the last decade. For this post, I have prepared a subset CSV file that contains the stock price and volume information between May and September 2021.\n",
    "Each stock ticker will be represented as a separate node. We will store the price and volume information for each stock ticker as a linked list of stock trading days nodes. Using the linked list schema is a general graph model I use when modeling timeseries data in Neo4j. If you want to follow along with examples in this blog post, I suggest you open a blank project in Neo4j Sandbox. Neo4j Sandbox provides free cloud instances of Neo4j database that come pre-installed with both the  APOC and Graph Data Science plugins. You can copy the following Cypher query in Neo4j Browser to import the stock information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3ed092",
   "metadata": {
    "id": "4c3ed092"
   },
   "outputs": [],
   "source": [
    "# Define Neo4j connections\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "host = 'bolt://44.192.98.23:7687'\n",
    "user = 'neo4j'\n",
    "password = 'circulations-bypass-bottoms'\n",
    "driver = GraphDatabase.driver(host,auth=(user, password))\n",
    "\n",
    "def run_query(query):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        return pd.DataFrame([r.values() for r in result], columns=result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf4253",
   "metadata": {
    "id": "fadf4253",
    "outputId": "00dd4f98-d9b6-4dfa-bffd-72631dff0e46"
   },
   "outputs": [],
   "source": [
    "run_query(\"\"\"\n",
    "USING PERIODIC COMMIT\n",
    "LOAD CSV WITH HEADERS FROM \"https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/stocks/stock_prices.csv\" as row\n",
    "MERGE (s:Stock{name:row.Name})\n",
    "CREATE (s)-[:TRADING_DAY]->(:StockTradingDay{date: date(row.Date), close:toFloat(row.Close), volume: toFloat(row.Volume)})\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d07fc53",
   "metadata": {
    "id": "6d07fc53"
   },
   "source": [
    "Next, we need to create a linked list between stock trading days nodes. We can easily create a linked list with the `apoc.nodes.link` procedure. We will also collect the closing prices by days of stocks and store them as a list property of the stock node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847602fd",
   "metadata": {
    "id": "847602fd",
    "outputId": "e7e8cf68-e5c4-4043-9861-234865c2a56e"
   },
   "outputs": [],
   "source": [
    "run_query(\"\"\"\n",
    "MATCH (s:Stock)-[:TRADING_DAY]->(day)\n",
    "WITH s, day\n",
    "ORDER BY day.date ASC\n",
    "WITH s, collect(day) as nodes, collect(day.close) as closes\n",
    "SET s.close_array = closes\n",
    "WITH nodes\n",
    "CALL apoc.nodes.link(nodes, 'NEXT_DAY')\n",
    "RETURN distinct 'done' AS result\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ffdb96",
   "metadata": {
    "id": "11ffdb96"
   },
   "source": [
    "# Inferring relationships based on the correlation coefficient\n",
    "We will use the Pearson similarity as the correlation metric. The authors of the above-mentioned research paper use more sophisticated correlation metrics, but that is beyond the scope of this blog post. The input to the Pearson similarity algorithm will be the ordered list of closing prices we produced in the previous step. The algorithm will calculate the correlation coefficient and store the results as relationships between most correlating stocks. I have used the topKparameter value of 3, so each stock will be connected to the three most correlating stock tickers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3ff0dd",
   "metadata": {
    "id": "8b3ff0dd",
    "outputId": "31ac7fbd-9a00-497c-d122-8c4553c61eac"
   },
   "outputs": [],
   "source": [
    "run_query(\"\"\"\n",
    "MATCH (s:Stock)\n",
    "WITH {item:id(s), weights: s.close_array} AS stockData\n",
    "WITH collect(stockData) AS input\n",
    "CALL gds.alpha.similarity.pearson.write({\n",
    "  data: input,\n",
    "  topK: 3,\n",
    "  similarityCutoff: 0.2\n",
    "})\n",
    "YIELD nodes, similarityPairs\n",
    "RETURN nodes, similarityPairs\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a33d0c",
   "metadata": {
    "id": "13a33d0c"
   },
   "source": [
    "As mentioned, the algorithm produced new SIMILAR relationships between stock ticker nodes.\n",
    "We can now run a community detection algorithm to identify various clusters of correlating stocks. I have decided to use the Louvain Modularity in this example. The community ids will be stored as node properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59216e2",
   "metadata": {
    "id": "f59216e2",
    "outputId": "d5a10c0e-3b7b-45f2-a6f1-1c3649e8598f"
   },
   "outputs": [],
   "source": [
    "run_query(\"\"\"\n",
    "CALL gds.louvain.write({\n",
    "  nodeProjection:'Stock',\n",
    "  relationshipProjection:'SIMILAR',\n",
    "  writeProperty:'louvain'\n",
    "})\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e11de4",
   "metadata": {
    "id": "b6e11de4"
   },
   "source": [
    "With such small graphs, I find the best way to examine community detection results is to simply produce a network visualization. Following the research paper idea, you would want to invest in stocks from different communities to diversify your risk and increase profits. You could pick the stocks from each community using a linear regression slope to indicate their performance. I found there is a simple linear regression model available as an `apoc.math.regr` procedure. Read more about it in the documentation. Unfortunately, the developers had different data model in mind for performing linear regression, so we first have to adjust the graph model to fit the procedure input. In the first step, we add a secondary label to the stock trading days nodes that indicate the stock ticker it represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca47c1d9",
   "metadata": {
    "id": "ca47c1d9",
    "outputId": "67812f6e-85fe-4fce-f6b5-49e5ce82a424"
   },
   "outputs": [],
   "source": [
    "run_query(\"\"\"\n",
    "MATCH (s:Stock)-[:TRADING_DAY]->(day)\n",
    "CALL apoc.create.addLabels( day, [s.name]) YIELD node\n",
    "RETURN distinct 'done'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02a835",
   "metadata": {
    "id": "ef02a835"
   },
   "source": [
    "Next, we need to calculate the x-axis index values. We will simply assign an index value of zero to each stock's first trading day and increment the index value for each subsequent trading day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef7f2c",
   "metadata": {
    "id": "ccef7f2c",
    "outputId": "36dfa19b-5bef-40de-962c-cc4278976115"
   },
   "outputs": [],
   "source": [
    "run_query(\"\"\"\n",
    "MATCH (s:Stock)-[:TRADING_DAY]->(day)\n",
    "WHERE NOT ()-[:NEXT_DAY]->(day)\n",
    "MATCH p=(day)-[:NEXT_DAY*0..]->(next_day)\n",
    "SET next_day.index = length(p)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58411c92",
   "metadata": {
    "id": "58411c92"
   },
   "source": [
    "Now that our graph model fits the linear regression procedure in APOC, we can go ahead and calculate the slope value of the fitted line. In a more serious setting, we would probably want to scale the closing prices, but we will skip it for this demonstration. The slope value will be stored as a node property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2880d629",
   "metadata": {
    "id": "2880d629",
    "outputId": "449a7491-d4d3-4ba8-a1dd-c574beb4abc0"
   },
   "outputs": [],
   "source": [
    "run_query(\"\"\"\n",
    "MATCH (s:Stock)\n",
    "CALL apoc.math.regr(s.name, 'close', 'index') YIELD slope\n",
    "SET s.slope = slope;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b33cf",
   "metadata": {
    "id": "832b33cf"
   },
   "source": [
    "As a last step, we can recommend the top three performing stocks from each community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f6c3fe",
   "metadata": {
    "id": "d3f6c3fe",
    "outputId": "555a070e-ffee-4849-bdc3-6838bfea705d"
   },
   "outputs": [],
   "source": [
    "run_query(\"\"\"\n",
    "MATCH (s:Stock)\n",
    "WITH s.louvain AS community, s.slope AS slope, s.name AS ticker\n",
    "ORDER BY slope DESC\n",
    "RETURN community, collect(ticker)[..3] as potential_investments\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848c6563",
   "metadata": {
    "id": "848c6563"
   },
   "source": [
    "# Conclusion\n",
    "This is not financial advice, do your own research before investing. Even so, in this blog post, I only looked at a 90-day window for 100 stocks. If you wanted to get more serious, you would probably want to collect a more extensive dataset and fine-tune the correlation coefficient calculation. Not only that, but a simple linear regression might not be the best indicator of stock performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c591d1",
   "metadata": {
    "id": "83c591d1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Stock diversification analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
