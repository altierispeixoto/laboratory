{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introdução "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O valor **tf–idf** (abreviação do inglês term frequency–inverse document frequency, que significa frequência do termo–inverso da frequência nos documentos),\n",
    "é uma medida estatística que tem o intuito de indicar a importância de uma palavra de um documento em relação a uma coleção de documentos ou em um [corpus linguístico](https://pt.wikipedia.org/wiki/Corpus_lingu%C3%ADstico).\n",
    "Ela é frequentemente utilizada como fator de ponderação na recuperação de informações e na mineração de dados.\n",
    "\n",
    "O valor **tf–idf** de uma palavra aumenta proporcionalmente à medida que aumenta o número de ocorrências dela em um documento, no entanto, esse valor é equilibrado pela \n",
    "frequência da palavra no corpus. Isso auxilia a distinguir o fato da ocorrência de algumas palavras serem geralmente mais comuns que outras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"formula.png\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pseudocode.png\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequência do termo (tf)\n",
    "\n",
    "Suponha que foram selecionados uma coleção de documento de textos em português e que nós desejamos determinar qual deles tem maior relação com a frase \"uma vaca amarela\". Uma maneira simples de iniciar essa análise seria simplesmente descartar todos os documentos que não contém as palavras \"uma\", \"vaca\" e \"amarela\", mas apenas esse procedimento não seria suficiente para completar a análise, pois muitos documentos provavelmente possuem as três palavras. Assim, para melhorar a distinção entre elas, nós podemos **contar o número de vezes que um dos termos ocorre em cada documento e somar esse valor; o número de vezes que um termo ocorre em um documento é a frequência do termo**.\n",
    "\n",
    "A primeira forma de ponderação de termos é atribuída a Hans Peter Luhn (1957) e se baseia na suposição de Luhn:\n",
    "\n",
    "- O peso de um termo que ocorre em um documento é diretamente proporcional à sua frequência.\n",
    "\n",
    "TF = (Frequency of the word in the sentence) / (Total number of words in the sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img  src=\"tf.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverso da frequência nos documentos (idf)\n",
    "No entanto, como o termo \"uma\" é muito comum, isso vai dar ênfase em documentos que utilizam essa palavra com mais frequência, sem dar a ênfase apropriada para termos com mais \n",
    "significado como \"vaca\" e \"amarela\". O termo \"uma\" não é uma boa palavra-chave para distinguir documentos relevantes de não-relevantes em comparação com as palavras \"vaca\" e \"amarela\". \n",
    "Assim, o inverso da frequência do termo nos documentos é incorporado para diminuir o peso dos termos que ocorrem mais frequentemente no conjunto de textos selecionados, ao mesmo tempo\n",
    "que aumenta o peso daqueles que ocorrem raramente.\n",
    "\n",
    "Karen Spärck Jones (1972) concebeu uma interpretação estatística do termo **IDF**, que se tornou um conceito base para a ponderação de termos:\n",
    "\n",
    "- A especificidade de um termo pode ser quantificada por uma **função inversa** do número de documentos em que ele ocorre.\n",
    "\n",
    "IDF: (Total number of sentences (documents))/(Number of sentences (documents) containing the word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img  src=\"idf.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'this is the first document pipoca pipoca pipoca',\n",
    "    'this document is the second document pipoca pipoca pipoca',\n",
    "    'and this is the third one pipoca pipoca pipoca',\n",
    "    'as this the first document amesterda'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Implementação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tfidf():\n",
    "    \n",
    "    def __init__(self, corpus):\n",
    "        self.dictionary = set()\n",
    "        self.bow_list = []\n",
    "        self.word_dict_list = []\n",
    "        self.tf_list = []\n",
    "        \n",
    "        self.idfs = {}\n",
    "        self.tf_idfs = []\n",
    "        \n",
    "        for doc in corpus:\n",
    "            wordlist = doc.split(\" \")\n",
    "            self.bow_list.append(wordlist)\n",
    "            self.dictionary= self.dictionary.union(set(wordlist))\n",
    "            \n",
    "        for doc in corpus:    \n",
    "            self.word_dict_list.append(dict.fromkeys(self.dictionary, 0))\n",
    "    \n",
    "        for bow, wordDict  in zip(self.bow_list, self.word_dict_list) :\n",
    "            for word in bow:\n",
    "                wordDict[word]+=1\n",
    "        \n",
    "    def computeTF(self,wordDict, bow):\n",
    "        import math\n",
    "        \"\"\"\n",
    "        TF = (Frequency of the word in the sentence) / (Total number of words in the sentence)\n",
    "        \"\"\"\n",
    "        tfDict = {}\n",
    "        bowCount = len(bow)\n",
    "        for word, count in wordDict.items():\n",
    "            tfDict[word] = count/float(bowCount)\n",
    "        return tfDict\n",
    "    \n",
    "    def computeTFIDF(self, tfBow, idfs):\n",
    "        tfidf = {}\n",
    "        for word, val in tfBow.items():\n",
    "            tfidf[word] = val*idfs[word]\n",
    "        return tfidf\n",
    "        \n",
    "    def computeIDF(self, docList):\n",
    "        \"\"\"\n",
    "        IDF: (Total number of sentences (documents))/(Number of sentences (documents) containing the word)\n",
    "        \"\"\"\n",
    "        import math\n",
    "        idfDict = {}\n",
    "        N = len(docList)\n",
    "\n",
    "        idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "        for doc in docList:\n",
    "            for word, val in doc.items():\n",
    "                if val > 0:\n",
    "                    idfDict[word] += 1\n",
    "\n",
    "        for word, val in idfDict.items():\n",
    "            idfDict[word] = math.log( 1+ N / 1+ float(val) ) +1\n",
    "        \n",
    "        return idfDict\n",
    "\n",
    "    def fit(self):\n",
    "        \n",
    "        self.idfs = self.computeIDF(self.word_dict_list)\n",
    "        \n",
    "        for bow, wordDict  in zip(self.bow_list, self.word_dict_list) :\n",
    "            tfbow = self.computeTF(wordDict, bow)\n",
    "            self.tf_list.append(self.computeTF(wordDict, bow))\n",
    "            self.tf_idfs.append(self.computeTFIDF(tfbow, self.idfs))\n",
    "            \n",
    "        return  self.tf_idfs  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Teste "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary :{'one', 'first', 'third', 'document', 'is', 'amesterda', 'the', 'and', 'as', 'second', 'this', 'pipoca'}\n"
     ]
    }
   ],
   "source": [
    "tfidf = Tfidf(corpus)\n",
    "print(f\"dictionary :{tfidf.dictionary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag Of words:[['this', 'is', 'the', 'first', 'document', 'pipoca', 'pipoca', 'pipoca'], ['this', 'document', 'is', 'the', 'second', 'document', 'pipoca', 'pipoca', 'pipoca'], ['and', 'this', 'is', 'the', 'third', 'one', 'pipoca', 'pipoca', 'pipoca'], ['as', 'this', 'the', 'first', 'document', 'amesterda']]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Bag Of words:{tfidf.bow_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Ocurrences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amesterda</th>\n",
       "      <th>and</th>\n",
       "      <th>as</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>pipoca</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amesterda  and  as  document  first  is  one  pipoca  second  the  third  \\\n",
       "0          0    0   0         1      1   1    0       3       0    1      0   \n",
       "1          0    0   0         2      0   1    0       3       1    1      0   \n",
       "2          0    1   0         0      0   1    1       3       0    1      1   \n",
       "3          1    0   1         1      1   0    0       0       0    1      0   \n",
       "\n",
       "   this  \n",
       "0     1  \n",
       "1     1  \n",
       "2     1  \n",
       "3     1  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf.word_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfs = tfidf.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amesterda</th>\n",
       "      <th>and</th>\n",
       "      <th>as</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>pipoca</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amesterda       and        as  document     first        is       one  \\\n",
       "0   0.000000  0.000000  0.000000  0.125000  0.125000  0.125000  0.000000   \n",
       "1   0.000000  0.000000  0.000000  0.222222  0.000000  0.111111  0.000000   \n",
       "2   0.000000  0.111111  0.000000  0.000000  0.000000  0.111111  0.111111   \n",
       "3   0.166667  0.000000  0.166667  0.166667  0.166667  0.000000  0.000000   \n",
       "\n",
       "     pipoca    second       the     third      this  \n",
       "0  0.375000  0.000000  0.125000  0.000000  0.125000  \n",
       "1  0.333333  0.111111  0.111111  0.000000  0.111111  \n",
       "2  0.333333  0.000000  0.111111  0.111111  0.111111  \n",
       "3  0.000000  0.000000  0.166667  0.000000  0.166667  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf.tf_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amesterda</th>\n",
       "      <th>and</th>\n",
       "      <th>as</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>pipoca</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.791759</td>\n",
       "      <td>2.791759</td>\n",
       "      <td>2.791759</td>\n",
       "      <td>3.079442</td>\n",
       "      <td>2.94591</td>\n",
       "      <td>3.079442</td>\n",
       "      <td>2.791759</td>\n",
       "      <td>3.079442</td>\n",
       "      <td>2.791759</td>\n",
       "      <td>3.197225</td>\n",
       "      <td>2.791759</td>\n",
       "      <td>3.197225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amesterda       and        as  document    first        is       one  \\\n",
       "0   2.791759  2.791759  2.791759  3.079442  2.94591  3.079442  2.791759   \n",
       "\n",
       "     pipoca    second       the     third      this  \n",
       "0  3.079442  2.791759  3.197225  2.791759  3.197225  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([tfidf.idfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amesterda</th>\n",
       "      <th>and</th>\n",
       "      <th>as</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>pipoca</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.38493</td>\n",
       "      <td>0.368239</td>\n",
       "      <td>0.38493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.154791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.399653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.399653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.68432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.34216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.026481</td>\n",
       "      <td>0.310195</td>\n",
       "      <td>0.355247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.34216</td>\n",
       "      <td>0.310195</td>\n",
       "      <td>1.026481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355247</td>\n",
       "      <td>0.310195</td>\n",
       "      <td>0.355247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.465293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465293</td>\n",
       "      <td>0.51324</td>\n",
       "      <td>0.490985</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.532871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.532871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amesterda       and        as  document     first       is       one  \\\n",
       "0   0.000000  0.000000  0.000000   0.38493  0.368239  0.38493  0.000000   \n",
       "1   0.000000  0.000000  0.000000   0.68432  0.000000  0.34216  0.000000   \n",
       "2   0.000000  0.310195  0.000000   0.00000  0.000000  0.34216  0.310195   \n",
       "3   0.465293  0.000000  0.465293   0.51324  0.490985  0.00000  0.000000   \n",
       "\n",
       "     pipoca    second       the     third      this  \n",
       "0  1.154791  0.000000  0.399653  0.000000  0.399653  \n",
       "1  1.026481  0.310195  0.355247  0.000000  0.355247  \n",
       "2  1.026481  0.000000  0.355247  0.310195  0.355247  \n",
       "3  0.000000  0.000000  0.532871  0.000000  0.532871  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação com o Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "vectorizer.get_feature_names()[:5]\n",
    "\n",
    "features_array = np.array(vectorizer.get_feature_names())\n",
    "features_array[:5]\n",
    "\n",
    "data = X.todense().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amesterda</th>\n",
       "      <th>and</th>\n",
       "      <th>as</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>pipoca</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268583</td>\n",
       "      <td>0.331753</td>\n",
       "      <td>0.268583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.805749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.237080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.711241</td>\n",
       "      <td>0.371432</td>\n",
       "      <td>0.193829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231246</td>\n",
       "      <td>0.362292</td>\n",
       "      <td>0.693738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189059</td>\n",
       "      <td>0.362292</td>\n",
       "      <td>0.189059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.528987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.528987</td>\n",
       "      <td>0.337645</td>\n",
       "      <td>0.417059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.276047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.276047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amesterda       and        as  document     first        is       one  \\\n",
       "0   0.000000  0.000000  0.000000  0.268583  0.331753  0.268583  0.000000   \n",
       "1   0.000000  0.000000  0.000000  0.474161  0.000000  0.237080  0.000000   \n",
       "2   0.000000  0.362292  0.000000  0.000000  0.000000  0.231246  0.362292   \n",
       "3   0.528987  0.000000  0.528987  0.337645  0.417059  0.000000  0.000000   \n",
       "\n",
       "     pipoca    second       the     third      this  \n",
       "0  0.805749  0.000000  0.219584  0.000000  0.219584  \n",
       "1  0.711241  0.371432  0.193829  0.000000  0.193829  \n",
       "2  0.693738  0.000000  0.189059  0.362292  0.189059  \n",
       "3  0.000000  0.000000  0.276047  0.000000  0.276047  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=features_array)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['document', 'first', 'is', 'the', 'this']\n",
      "['document', 'is', 'second', 'the', 'this']\n",
      "['and', 'is', 'one', 'the', 'third', 'this']\n",
      "['amesterda', 'as', 'document', 'first', 'the', 'this']\n"
     ]
    }
   ],
   "source": [
    "for i in df.iterrows():\n",
    "    values = i[1].values.tolist()\n",
    "    print([features_array[i] for i, v in enumerate(values) if 0.0 < v < 0.6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação com o Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------------------------------+-------------------------------------------------------------------+\n",
      "|label|sentence                                                 |words                                                              |\n",
      "+-----+---------------------------------------------------------+-------------------------------------------------------------------+\n",
      "|0.0  |this is the first document pipoca pipoca pipoca          |[this, is, the, first, document, pipoca, pipoca, pipoca]           |\n",
      "|0.0  |this document is the second document pipoca pipoca pipoca|[this, document, is, the, second, document, pipoca, pipoca, pipoca]|\n",
      "|1.0  |and this is the third one pipoca pipoca pipoca           |[and, this, is, the, third, one, pipoca, pipoca, pipoca]           |\n",
      "|1.0  |as this the first document                               |[as, this, the, first, document]                                   |\n",
      "+-----+---------------------------------------------------------+-------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer,CountVectorizer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "spark = SparkSession.builder.appName('abc').getOrCreate()\n",
    "\n",
    "sentenceData = spark.createDataFrame([\n",
    "    (0.0, 'this is the first document pipoca pipoca pipoca'),\n",
    "    (0.0, 'this document is the second document pipoca pipoca pipoca'),\n",
    "    (1.0, 'and this is the third one pipoca pipoca pipoca'),\n",
    "    (1.0, 'as this the first document')\n",
    "    \n",
    "], [\"label\", \"sentence\"])\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(sentenceData)\n",
    "wordsData.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------------------------------+-------------------------------------------------------------------+--------------------------------------------------+\n",
      "|label|sentence                                                 |words                                                              |cv_features                                       |\n",
      "+-----+---------------------------------------------------------+-------------------------------------------------------------------+--------------------------------------------------+\n",
      "|0.0  |this is the first document pipoca pipoca pipoca          |[this, is, the, first, document, pipoca, pipoca, pipoca]           |(11,[0,1,2,3,4,5],[3.0,1.0,1.0,1.0,1.0,1.0])      |\n",
      "|0.0  |this document is the second document pipoca pipoca pipoca|[this, document, is, the, second, document, pipoca, pipoca, pipoca]|(11,[0,1,2,3,4,10],[3.0,1.0,1.0,2.0,1.0,1.0])     |\n",
      "|1.0  |and this is the third one pipoca pipoca pipoca           |[and, this, is, the, third, one, pipoca, pipoca, pipoca]           |(11,[0,1,2,4,6,8,9],[3.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|1.0  |as this the first document                               |[as, this, the, first, document]                                   |(11,[1,2,3,5,7],[1.0,1.0,1.0,1.0,1.0])            |\n",
      "+-----+---------------------------------------------------------+-------------------------------------------------------------------+--------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"cv_features\") #vocabSize=3, minDF=2.0\n",
    "model = cv.fit(wordsData)\n",
    "\n",
    "featurizedData = model.transform(wordsData)\n",
    "featurizedData.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pipoca', 'this', 'the', 'document', 'is', 'first', 'third', 'as', 'one', 'and', 'second']\n"
     ]
    }
   ],
   "source": [
    "print(model.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- sentence: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- cv_features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurizedData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+--------+---+-----+-----+---+---+---+------+\n",
      "|pipoca|this|the|document| is|first|third| as|one|and|second|\n",
      "+------+----+---+--------+---+-----+-----+---+---+---+------+\n",
      "|   3.0| 1.0|1.0|     1.0|1.0|  1.0|  0.0|0.0|0.0|0.0|   0.0|\n",
      "|   3.0| 1.0|1.0|     2.0|1.0|  0.0|  0.0|0.0|0.0|0.0|   1.0|\n",
      "|   3.0| 1.0|1.0|     0.0|1.0|  0.0|  1.0|0.0|1.0|1.0|   0.0|\n",
      "|   0.0| 1.0|1.0|     1.0|0.0|  1.0|  0.0|1.0|0.0|0.0|   0.0|\n",
      "+------+----+---+--------+---+-----+-----+---+---+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_udf = F.udf(lambda vector: vector.toArray().tolist(),ArrayType(DoubleType()))\n",
    "\n",
    "colvalues = featurizedData.select(vector_udf('cv_features').alias('features')).collect()\n",
    "\n",
    "spark.createDataFrame(list(map(lambda x:x.features,colvalues)),model.vocabulary).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------------------------------+-------------------------------------------------------------------+--------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|sentence                                                 |words                                                              |cv_features                                       |idf_features                                                                                                                  |\n",
      "+-----+---------------------------------------------------------+-------------------------------------------------------------------+--------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0.0  |this is the first document pipoca pipoca pipoca          |[this, is, the, first, document, pipoca, pipoca, pipoca]           |(11,[0,1,2,3,4,5],[3.0,1.0,1.0,1.0,1.0,1.0])      |(11,[0,1,2,3,4,5],[0.6694306539426294,0.0,0.0,0.22314355131420976,0.22314355131420976,0.5108256237659907])                    |\n",
      "|0.0  |this document is the second document pipoca pipoca pipoca|[this, document, is, the, second, document, pipoca, pipoca, pipoca]|(11,[0,1,2,3,4,10],[3.0,1.0,1.0,2.0,1.0,1.0])     |(11,[0,1,2,3,4,10],[0.6694306539426294,0.0,0.0,0.44628710262841953,0.22314355131420976,0.9162907318741551])                   |\n",
      "|1.0  |and this is the third one pipoca pipoca pipoca           |[and, this, is, the, third, one, pipoca, pipoca, pipoca]           |(11,[0,1,2,4,6,8,9],[3.0,1.0,1.0,1.0,1.0,1.0,1.0])|(11,[0,1,2,4,6,8,9],[0.6694306539426294,0.0,0.0,0.22314355131420976,0.9162907318741551,0.9162907318741551,0.9162907318741551])|\n",
      "|1.0  |as this the first document                               |[as, this, the, first, document]                                   |(11,[1,2,3,5,7],[1.0,1.0,1.0,1.0,1.0])            |(11,[1,2,3,5,7],[0.0,0.0,0.22314355131420976,0.5108256237659907,0.9162907318741551])                                          |\n",
      "+-----+---------------------------------------------------------+-------------------------------------------------------------------+--------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idf = IDF(inputCol=\"cv_features\", outputCol=\"idf_features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "\n",
    "rescaledData.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----+---+-------------------+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|            pipoca|this|the|           document|                 is|             first|             third|                as|               one|               and|            second|\n",
      "+------------------+----+---+-------------------+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|0.6694306539426294| 0.0|0.0|0.22314355131420976|0.22314355131420976|0.5108256237659907|               0.0|               0.0|               0.0|               0.0|               0.0|\n",
      "|0.6694306539426294| 0.0|0.0|0.44628710262841953|0.22314355131420976|               0.0|               0.0|               0.0|               0.0|               0.0|0.9162907318741551|\n",
      "|0.6694306539426294| 0.0|0.0|                0.0|0.22314355131420976|               0.0|0.9162907318741551|               0.0|0.9162907318741551|0.9162907318741551|               0.0|\n",
      "|               0.0| 0.0|0.0|0.22314355131420976|                0.0|0.5108256237659907|               0.0|0.9162907318741551|               0.0|               0.0|               0.0|\n",
      "+------------------+----+---+-------------------+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "colvalues = rescaledData.select(vector_udf('idf_features').alias('features')).collect()\n",
    "\n",
    "spark.createDataFrame(list(map(lambda x:x.features,colvalues)),model.vocabulary).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/how-sklearns-tf-idf-is-different-from-the-standard-tf-idf-275fa582e73d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/4494134497577204/2690176961360097/6933319862459084/latest.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/39546671/handle-unseen-categorical-string-spark-countvectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.tfidf.com/https://codelabs.developers.google.com/codelabs/spark-nlp/#7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.tfidf.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
